{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The cell below is for you to keep track of the libraries used and install those libraries quickly\n",
    "##### Ensure that the proper library names are used and the syntax of `%pip install PACKAGE_NAME` is followed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyarrow\n",
      "  Downloading pyarrow-15.0.0-cp39-cp39-win_amd64.whl (24.9 MB)\n",
      "     --------------------------------------- 24.9/24.9 MB 17.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy<2,>=1.16.6 in c:\\users\\tange\\anaconda3\\lib\\site-packages (from pyarrow) (1.21.5)\n",
      "Installing collected packages: pyarrow\n",
      "Successfully installed pyarrow-15.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#%pip install pandas \n",
    "#%pip install matplotlib\n",
    "#%pip install pyarrow\n",
    "#%pip install seaborn\n",
    "#%pip install scikit-learn\n",
    "#%pip install matplotlib\n",
    "\n",
    "# add commented pip installation lines for packages used as shown above for ease of testing\n",
    "# the line should be of the format %pip install PACKAGE_NAME "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DO NOT CHANGE** the filepath variable\n",
    "##### Instead, create a folder named 'data' in your current working directory and \n",
    "##### have the .parquet file inside that. A relative path *must* be used when loading data into pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can have as many cells as you want for code\n",
    "import pandas as pd\n",
    "filepath = \"./data/catB_train.parquet\" \n",
    "# the initialised filepath MUST be a relative path to a folder named data that contains the parquet file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ALL** Code for machine learning and dataset analysis should be entered below. \n",
    "##### Ensure that your code is clear and readable.\n",
    "##### Comments and Markdown notes are advised to direct attention to pieces of code you deem useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan  1.]\n",
      "F1 score: 0.989023521026372\n"
     ]
    }
   ],
   "source": [
    "###...code...###\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import f1_score\n",
    "from datetime import date\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "### 1. DATA PROCESSING\n",
    "# read\n",
    "df = pd.read_parquet('./data/catB_train.parquet')\n",
    "hidden_data = df.copy(deep=True)\n",
    "\n",
    "# Investigate target column and understand the data\n",
    "# Since target column consists only of NaN or 1, convert NaNs to 0.\n",
    "print(df[\"f_purchase_lh\"].unique())\n",
    "\n",
    "# Step 1: Clean f_purchase_lh\n",
    "df['f_purchase_lh'] = df['f_purchase_lh'].fillna(0)\n",
    "\n",
    "# Label encoder handles non-numerical data such as annual income. Since annual income is in the format: C.60K-100K,\n",
    "# Convert String labels such as C.60K-100K to labels like 0,1,2,3,4 so that the model can parse the data\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "## Labelling Client Type\n",
    "df['clttype'] = label_encoder.fit_transform(df['clttype'])\n",
    "\n",
    "## Labelling annual income categories\n",
    "df['annual_income_est']= label_encoder.fit_transform(df['annual_income_est'])\n",
    "\n",
    "## Convert date of birth to age\n",
    "df['cltdob_fix'] = df['cltdob_fix'].replace(to_replace='None', value=np.nan).dropna()\n",
    "df['cltdob_fix'] = pd.to_datetime(df['cltdob_fix'], format='%Y-%m-%d')\n",
    "def calculate_age(born):\n",
    "    today = date.today()\n",
    "    return today.year - born.year - ((today.month, today.day) < (born.month, born.day))\n",
    "df['cltdob_fix'] = df['cltdob_fix'].apply(calculate_age)\n",
    "\n",
    "## Drop NA for purpose of training the model\n",
    "df['cltdob_fix'] = df['cltdob_fix'].dropna()\n",
    "### DATA PROCESSING\n",
    "\n",
    "\n",
    "\n",
    "### 2. CORRELATION MATRIX & HEATMAP FOR FEATURE SELECTION\n",
    "## Using Correlation matrix, we selected all features/variables with a correlation of > 5% to the target variable\n",
    "## Uncomment code below to see Heatmap of correlation matrix\n",
    "'''\n",
    "columns_to_test = [\"flg_gi_claim\",\"flg_is_proposal\",\"is_housewife_retiree\", \"is_sg_pr\", \"is_class_1_2\",\"annual_income_est\",\"n_months_last_bought_products\"\n",
    "                   ,\"flg_latest_being_lapse\",\"recency_lapse\", \"recency_cancel\",\"tot_inforce_pols\",\"f_mindef_mha\",\"recency_clmcon\",\"recency_giclaim\",\"cltdob_fix\",\"f_purchase_lh\"]\n",
    "\n",
    "# Test Correlation matrix\n",
    "corr_matrix = df.corr()\n",
    "print(corr_matrix)\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.show()\n",
    "'''\n",
    "### CORRELATION MATRIX & HEATMAP FOR FEATURE SELECTION\n",
    "\n",
    "\n",
    "### 3. FILTERING & UPSAMPLING\n",
    "columns_to_keep = [\"flg_gi_claim\",\"flg_is_proposal\",\"is_housewife_retiree\", \"is_sg_pr\", \"is_class_1_2\",\"annual_income_est\",\"n_months_last_bought_products\"\n",
    "                   ,\"flg_latest_being_lapse\",\"recency_lapse\", \"recency_cancel\",\"tot_inforce_pols\",\"f_mindef_mha\",\"recency_clmcon\",\"recency_giclaim\",\"cltdob_fix\",\"f_purchase_lh\"]\n",
    "\n",
    "df = df[columns_to_keep]\n",
    "df = df.fillna(0)\n",
    "\n",
    "# Separate majority and minority classes\n",
    "df_majority = df[df['f_purchase_lh'] == 0]\n",
    "df_minority = df[df['f_purchase_lh'] == 1]\n",
    "\n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority,\n",
    "                                 replace=True,     # Sample with replacement\n",
    "                                 n_samples=17282,  # to match majority class\n",
    "                                 random_state=42)  # reproducible results\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "df = df_upsampled\n",
    "### FILTERING AND UPSAMPLING\n",
    "\n",
    "\n",
    "### 4. TRAINING THE MODEL\n",
    "## We selected Random Forest since it is robust to overfitting and tends to perform well without much hyperparameter tuning.\n",
    "X = df[[\"flg_gi_claim\",\"flg_is_proposal\",\"is_housewife_retiree\", \"is_sg_pr\", \"is_class_1_2\",\"annual_income_est\",\"n_months_last_bought_products\"\n",
    "                   ,\"flg_latest_being_lapse\",\"recency_lapse\", \"recency_cancel\",\"tot_inforce_pols\",\"f_mindef_mha\",\"recency_clmcon\",\"recency_giclaim\",\"cltdob_fix\"]]\n",
    "y = df[\"f_purchase_lh\"]\n",
    "\n",
    "# Split the dataset into training and testing sets with 20% for test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"F1 score:\", f1)\n",
    "### TRAINING THE MODEL\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The cell below is **NOT** to be removed\n",
    "##### The function is to be amended so that it accepts the given input (dataframe) and returns the required output (list). \n",
    "##### It is recommended to test the function out prior to submission\n",
    "-------------------------------------------------------------------------------------------------------------------------------\n",
    "##### The hidden_data parsed into the function below will have the same layout columns wise as the dataset *SENT* to you\n",
    "##### Thus, ensure that steps taken to modify the initial dataset to fit into the model are also carried out in the function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_hidden_data(hidden_data: pd.DataFrame) -> list:\n",
    "    '''DO NOT REMOVE THIS FUNCTION.\n",
    "\n",
    "The function accepts a dataframe as input and return an iterable (list)\n",
    "of binary classes as output.\n",
    "\n",
    "The function should be coded to test on hidden data\n",
    "and should include any preprocessing functions needed for your model to perform. \n",
    "    \n",
    "All relevant code MUST be included in this function.'''\n",
    "    hidden_data['cltdob_fix'] = hidden_data['cltdob_fix'].replace(to_replace='None', value=np.nan).dropna()\n",
    "    hidden_data['cltdob_fix'] = pd.to_datetime(hidden_data['cltdob_fix'], format='%Y-%m-%d')\n",
    "    hidden_data['cltdob_fix'] = hidden_data['cltdob_fix'].apply(calculate_age)\n",
    "\n",
    "    # Label encoding of income\n",
    "    hidden_data['annual_income_est']= label_encoder.fit_transform(hidden_data['annual_income_est'])\n",
    "\n",
    "    hidden_data['clttype'] = label_encoder.fit_transform(hidden_data['clttype']) \n",
    "    columns_to_keep = [\"flg_gi_claim\",\"flg_is_proposal\",\"is_housewife_retiree\", \"is_sg_pr\", \"is_class_1_2\",\"annual_income_est\",\"n_months_last_bought_products\"\n",
    "                       ,\"flg_latest_being_lapse\",\"recency_lapse\", \"recency_cancel\",\"tot_inforce_pols\",\"f_mindef_mha\",\"recency_clmcon\",\"recency_giclaim\",\"cltdob_fix\"]\n",
    "    hidden_data = hidden_data[columns_to_keep]\n",
    "    hidden_data = hidden_data.fillna(0)\n",
    "    result = rf_classifier.predict(hidden_data)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cell to check testing_hidden_data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# This cell should output a list of predictions.\n",
    "test_df = pd.read_parquet(filepath)\n",
    "test_df = test_df.drop(columns=[\"f_purchase_lh\"])\n",
    "print(testing_hidden_data(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please have the filename renamed and ensure that it can be run with the requirements above being met. All the best!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
